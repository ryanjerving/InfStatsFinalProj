---
title: "Statistical Inference with GSS Data"
output: 
  html_document: 
    fig_height: 4
    highlight: pygments
    theme: spacelab
---

## Setup

### Load packages

```{r load-packages, message = FALSE}

library(ggplot2)
library(dplyr)
library(statsr)

```

### Load data

```{r load-data}

load("gss.Rdata")

```

* * *

## Part 1: GSS Data

### How Collection Happens and Its Implications for the Scope of Inference

Since 1972, the National Opinion Research Center at the University of Chicago (NORC) has produced the **General Social Survey (GSS)** (initially, surveys were conducted annually; in recent decades, they have been biannual). As a broad survey of U.S. demographics and public opinion, the goal of the GSS is to have "provided politicians, policymakers, and scholars with a clear and unbiased perspective on what Americans think and feel about such issues as national spending priorities, crime and punishment, intergroup relations, and confidence in institutions" (see <http://gss.norc.org/>). 

Each edition of the survey between 1972 and 2004 drew a random **sample** of approximately 1,500 subjects from a target population of non-institutionalized English-speaking persons within the United States 18 years of age or over. Since 2006, Spanish-speaking persons have been added to this sample. In the `r max(gss$year)` edition provided through the Coursera MOOC *Inferential Statistics* from the *Statistic in R* sequence offered by Duke University, for example, the GSS interviewed `r nrow(gss %>% filter(year == max(gss$year)))` people: `r nrow(gss %>% filter(year == max(gss$year), sex == "Female"))` women, `r nrow(gss %>% filter(year == max(gss$year), sex == "Male"))` men; `r nrow(gss %>% filter(year == max(gss$year), race == "Black"))` black, `r nrow(gss %>% filter(year == max(gss$year), race == "White"))` white, and `r nrow(gss %>% filter(year == max(gss$year), race == "Other"))` other. These interviews are mostly conducted face-to-face (with a small number computer-assisted or by telephone), and typically take about one and a half hours to complete. And to the extent practicable, the exact wording of questions is retained from year to year to allow for cross-survey comparisons.

The survey's **study design** is observational rather than experimental: we can't draw conclusions about the direction of cause-and-effect for any correlations we might discover. But both the large sample size and the survey's independent random sampling method mean our findings should be generalizable to the broader target population and should allow for making solid inferential claims about the center and spread of this data.

Nevertheless, the choice to sample from only "non-institutionalized" adults means the data will likely underrepresent those types of people who are demographically *overrepresented* in the population of institutionalized U.S. adults --- not a minor consideration for a survey that attempts to cover such matters as the social attitudes toward race, income inequality, access to healthcare, and the role of government: questions such as those that we'll address below. 

* * *

## Part 2: Research Questions

Though the GSS ranges across a wide swatch of items of potential interest in 21st-century American culture and social life, for this project I'll be looking at a small subset of questions concerning **attitudes toward government intervention**: in matters of income inequality (`HELPPOOR`), healthcare (`HELPSICK`), the historical impact of race (`HELPBLK`), and in general (`HELPNOT`). 

Asking subjects to place themselves on a scale of 1 to 5, the survey asks:

* VAR: `HELPPOOR` -- Some people think that the government in Washington should do everything possible to improve the standard of living of all poor Americans; they are at Point 1 on this card. Other people think it is not the government's responsibility, and that each person should take care of himself; they are at Point 5 on this card.

* VAR: `HELPSICK` -- In general, some people think that it is the responsibility of the government in Washington to see to it that people have help in paying for doctors and hospital bills. Others think that these matters are not the responsibility of the federal government and that people should take care of these things themselves.

* VAR: `HELPBLK` -- Some people think that (Blacks/Negroes/African-Americans) have been discriminated against for so long that the government has a special obligation to help improve their living standards. Others believe that the government should not be giving special treatment to (Blacks/Negroes/African-Americans).

* VAR: `HELPNOT` -- Some people think that the government in Washington is trying to do too many things that should be left to individuals and private businesses. Others disagree and think that the government should do even more to solve our country's problems. Still others have opinions somewhere in between.

In what follows below, I'd like to explore the answers to these questions and how those answers have shifted -- whether in tandem, or in different directions -- in the surveys done between 2008 and 2012, covering a period of American history that brought attitudes toward these subjects into sharp focus: the election to the presidency of Barack Obama, the U.S.'s first black president; the passage of the Affordable Care Act under his administration, a controversial attempt at providing something like guaranteed healthcare coverage; the limited-government backlash movement known as the "Tea Party" that brought a wave of members into Congress in 2010 dedicated to the ideal of a sharply limited; and Obama's re-election in 2012, a result that set the stage for a swing of the pendulum in the next cycle of U.S. politics that brought about the very different politics represented by Donald Trump.

Specifically, I'd like to ask the following:

1. In 2012, how supportive/resistant were Americans to the idea that **race continues to matter** in U.S. life and **requires active measures** on the part of the federal government to address its persistent impact?

2. How did the level of support/resistance change between the years of Obama's election in 2008 and re-election in 2012, and **was that change significant**?

The answers to these questions should go some way toward helping us understand the grounds upon which U.S. racial politics have stood in the period since.

* * *

## Part 3: Exploratory data analysis

We'll start by taking an overview of how attitudes about the role of government in addressing racial inequality changed, or didn't, between 2008 and 2012.

LONG NOTE (FAIR WARNING: IF YOU DON'T CARE, SKIP!): In the version of the GSS dataset provided as part of the *Inferential Statistics* MOOC, `helpblk` and other variables have been **"cleaned"** to eliminate non-answers. Unfortunately, what this means in practice is that the range of responses for these questions has been transformed from a 5-level integer Likkert scale to a factored variable with just three levels -- in the case of `helpblk`, to just `Govt Help Blks`, `Agree With Both`, and `No Special Treatment`. In the original data, these were points 1, 3, and 5 on the scale, respectively, and responses along the 2 and 4 points of the scale have simply been eliminated in the cleaned version -- treated as non-responses. 

This isn't ideal from the perspective of giving us the whole picture. But since I plan to concentrate on those shifts at the end of the spectrum -- "Govt Help Blks" and "No Special Treatment" -- it will still work for our purposes (the counts for those responses are unchanged between the raw and cleaned versions of the dataset).

Nevertheless, I'd first like to at least get a count of the total respondents to this question along the five-point scale. So I'm going to go back to the original dataset available directly from the GSS to get the total number of respondents to this question from 2008 and 2012, which will then be available to use in the proportion calculations derived from the cleaned dataset.

```{r explore-full-dataset}

# WARNING: The following code uses what turns out to be a very large dataset from the GSS:
# 62,466 rows over 5,897 variables, and using 399.7 MB of memory if downloaded. 

# So, rather than ask you to run this here and bring your computer to a grinding halt, 
# I'll show you the steps I took -- which you could replicate on your own -- but comment them out
# and then just show the results and store them as variables for use in the rest of this analysis.

# To read in the data from the SPSS-ready format in which NORC provides the GSS data (inclusive through 2016),
# I'm following the guidelines of a tutorial by Douglas M. Wiig on his R Statistics and Programming blog at:
# https://dmwiig.net/2014/08/03/r-tutorial-using-r-to-work-with-datasets-from-the-norc-general-social-science-survey/

# First, we load in two libraries ("foreign" is native to R; you would need to install "Hmisc")

# library(foreign)
# library(Hmisc)

# Then read in the data from the SPSS (".sav") format in which NORC provides it.
# I downloaded this as .zip file "GSS7216_R3" to the folder in which my R project resides, from
# http://gss.norc.org/documents/spss/GSS_spss.zip

# gssFull <- spss.get("GSS7216_R3.sav", use.value.labels = TRUE)

# Now, we look at the distribution of the HELPBLK variable for 2008 and 2012. First, 2008:

# gssFull %>% filter(YEAR == 2008, !is.na(HELPBLK)) %>% group_by(HELPBLK) %>% summarise(count = n())

#  HELPBLK              count
#  <fct>                <int>
# 1 GOVT HELP BLKS         125
# 2 2                      107
# 3 AGREE WITH BOTH        440
# 4 4                      253
# 5 NO SPECIAL TREATMENT   383

# With:
# TOTAL                   1308

nhelpblk2008 = 1308

# And for 2012:

# gssFull %>% filter(YEAR == 2012, !is.na(HELPBLK)) %>% group_by(HELPBLK) %>% summarise(count = n())

#  HELPBLK              count
#  <fct>                <int>
# 1 GOVT HELP BLKS          93
# 2 2                      117
# 3 AGREE WITH BOTH        394
# 4 4                      231
# 5 NO SPECIAL TREATMENT   447

# With:
# TOTAL                   1282

nhelpblk2012 = 1282

# Now we have total non-NA responses for this question for both years, against which we can gauge the
# proportion of particular answers.

# And, just for historical interest (and because it actually complicates the point I'm trying to make!),
# here's 2016 -- the year of Donald J. Trump's election to the U.S. presidency:

# gssFull %>% filter(YEAR == 2016, !is.na(HELPBLK)) %>% group_by(HELPBLK) %>% summarise(count = n())

#  HELPBLK              count
#  <fct>                <int>
# 1 GOVT HELP BLKS         246
# 2 2                      220
# 3 AGREE WITH BOTH        608
# 4 4                      371
# 5 NO SPECIAL TREATMENT   430

# With:
# TOTAL                   1875

nhelpblk2016 = 1875

```

Which is to say: for the question on the obligation of the U.S. government to "help blacks" vs. provide "no special treatment," we have `r nhelpblk2008` total responses for 2008, and `r nhelpblk2012` responses in 2012. 

SHORT NOTE WITHIN A LONG NOTE: Though it was good R practice to go through the original raw dataset, there is a an easier "cheater's" way -- i.e., the sane person's way -- to get the same basic numbers. Namely, these are included as part of the published GSS's codebook for this data at <http://gss.norc.org/get-documentation>. (See pages 576 through 579 of the PDF)

We'll use these total reponse numbers for 2008 and 2012 as the basis for understanding the proportions of responses at either end of the spectrum -- "Govt Help Blks" and "No Special Treatment" -- for this question.

Let's see what those **proportions** were.

```{r number-of-subjects-answering-questions}

YesHelpblk2008 <- gss %>%
  filter(year == '2008' & !is.na(helpblk)) %>%
  group_by(helpblk) %>%
  summarise(count08 = n(), proportions08 = n()/nhelpblk2008)

YesHelpblk2008

YesHelpblk2012 <- gss %>%
  filter(year == '2012' & !is.na(helpblk)) %>%
  group_by(helpblk) %>%
  summarise(count12 = n(), proportions12 = n()/nhelpblk2012)

YesHelpblk2012

```

And let's also see **what that looks like** across these two editions of the survey:

```{r plot-helpblk-2008-vs-2012}

ggplot(YesHelpblk2008, 
       aes(x = helpblk, y = proportions08, fill = proportions08)) + geom_col()

ggplot(YesHelpblk2012, 
       aes(x = helpblk, y = proportions12, fill = proportions12)) + geom_col()

```

So... there *does* seem to have been a shift to the right on this question between 2008 and 2012 -- all puns intended -- with fewer respondents agreeing with the statement "that (Blacks/Negroes/African-Americans) have been discriminated against for so long that the government has a special obligation to help improve their living standards" (a 2.3% drop between the two surveys), and more respondents agreeing with the statement "that the government should not be giving special treatment to (Blacks/Negroes/African-Americans)" (a 5.6% increase). (The 2.9% drop in the "Agree With Both" proportion might also point to more polarized attitude on this question.)

**But are these changes significant?**

In the following section, we'll ask whether the tools of **statistical inference** can tell us, with confidence, whether these changes -- visually striking on their face -- are signficant or whether, on the other hand, they are simply differences we could expect within the normal range of sampling variation.

* * *

## Part 4: Inference

Our basic question about the shift in attitudes between 2008 and 2012 on the role government intervention in addressing race-based inequality is really two questions: 1) what do our sample proportions tell us about those attitudes in the target population in 2008 and 2012? and 2) Do the differences in the sample proportions between those survey years suggest a significant difference across that period for our target population of U.S. (non-institutionalized) adults?

### Question 1 - Sample Proportions

*Q: In 2012, how supportive/resistant were Americans to the idea that **race continues to matter** in U.S. life and **requires active measures** on the part of the federal government to address its persistent impact?*

To answer this question, we'll determine the sample proportions for the responses at the two far ends of the five-point spectrum on the GSS `helpblk` survey question for 2012, and construct **confidence intervals** around those proportions that allow us to state, with a 95% **confidence level**, that the true population parameter -- the proportion of the full population of non-institutionalized U.S. adults who we would expect answer in the same way -- would fall within the margin of error established by these intervals.

Our calculations depend on the premise of the **Central Limit Theorem**: that, given what we know about the shape and spread of responses within our sample, we can assume that with enough samples we would see a distribution of the sample statistic (in this case, the proportion of our sample answering a question a particular way) that would be centered on the true **population parameter**, with a **margin of error** determined by our desired level of confidence and inversely related to our sample size.

Certain **conditions** about our sample would need to be met for this to be the case:

* **Independence of observations** -- Since the survey design tells us the respondents are randomly chosen, and since their number ($\approx$ 1,500) is well under 10% of the total target U.S. population, this condition is met.
* **Sample size and skew** -- for 2012, both the number of successes and failures for each response (those giving a particular answer vs. those not) are well above the 10 used as the general cutoff for determining whether a sample meets CLT conditions.

With our conditions met, we can calculate the confidence interval as: 

$$CI = \hat{p} \pm Z^\star*SE$$

Where $\hat{p}$ is our sample success proportion, ${Z}^\star$is the critical value (cutoff for significance) for a Z-score distribution at our desired level of confidence (for a 95% confidence level, ${Z}^\star$is approx. 1.96), and $SE$ is the standard error assumed for sampling distributions at our proportion of sample successes and sample size. 

$SE$ is calculated as:

$$SE = \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$$

So let's construct a confidence interval for the population proportion of respondents who we would expect to answer that the government should be expected to play a role in addressing racial inequality in 2012:

```{r defining-variables-Govt12}

# Determine our desired confidence level at 95% and assign the Z* level associated with it.

z_star_95 <- qnorm(0.975)

# For 2012, find the proportion answering "Govt Help Blks" relative to the total number of respondents

nhelpblk12 <- nhelpblk2012     # from above

proportion_helpblk2012 <- gss %>%
  filter(year == '2012' & !is.na(helpblk) & helpblk == 'Govt Help Blks') %>%
  summarise(n()/nhelpblk12)
pGovt12 <- as.numeric(proportion_helpblk2012)

# Based on success proportion and sample size, calculated the Standard Error, and from it the Margin of Error

seGovt12 <- sqrt((pGovt12 * (1 - pGovt12))/nhelpblk12)
meGovt12 <- z_star_95 * seGovt12

```

THE RESULTS: In terms of 2012 respondents to the `helpblk` question, `r round(pGovt12, 3)` of `r nhelpblk12` who answered on the five-point scale put their response at 1 ('Govt Help Blks'). This means that our standard error $SE$ will be the square root of `r round(pGovt12, 3)` $*$ (1 - `r round((pGovt12), 3)`) divided by `r nhelpblk12` = `r round(seGovt12, 3)`, and our margin of error $ME$ will be our ${Z}^\star$ value `r z_star_95` $*$ our $SE$ value `r round(seGovt12, 3)` $=$ `r round(meGovt12, 3)`.

Our confidence interval $CI$ for this 2012 `Govt Help Blks` proportion will, therefore, be `r round(pGovt12, 3)` $\pm$ `r round(meGovt12, 3)`. This means we can say with 95% confidence that the true proportion of our 2012 target population who would say that the government should do more to help its African American citizens would fall between `r round((pGovt12 - meGovt12),3)` and `r round((pGovt12 + meGovt12), 3)`. 

We can now carry this out to the four data points and confidence intervals in which we're interested for this research question, which is to say, the proportion answering `helpblk` on either end of the 1 to 5 scale ('Govt Help Blks' and 'No Special Treatment') for 2012 vs. 2008.

```{r defining-variables-other}

# 2012, "No Special Treatment"

proportion_no_helpblk2012 <- gss %>%
  filter(year == '2012' & !is.na(helpblk) & helpblk == 'No Special Treatment') %>%
  summarise(n()/nhelpblk12)
pNoSpec12 <- as.numeric(proportion_no_helpblk2012)
meNoSpec12 <- z_star_95 * sqrt((pNoSpec12 * (1 - pNoSpec12))/nhelpblk12)

# 2008, "Govt Help Blks"

nhelpblk08 <- nhelpblk2008

proportion_helpblk2008 <- gss %>%
  filter(year == '2008' & !is.na(helpblk) & helpblk == 'Govt Help Blks') %>%
  summarise(n()/nhelpblk08)
pGovt08 <- as.numeric(proportion_helpblk2008)
meGovt08 <- z_star_95 * sqrt((pGovt08 * (1 - pGovt08))/nhelpblk08)

# 2008, "No Special Treatment"

proportion_no_helpblk2008 <- gss %>%
  filter(year == '2008' & !is.na(helpblk) & helpblk == 'No Special Treatment') %>%
  summarise(n()/nhelpblk08)
pNoSpec08 <- as.numeric(proportion_no_helpblk2008)
meNoSpec08 <- z_star_95 * sqrt((pNoSpec08 * (1 - pNoSpec08))/nhelpblk08)

```

The confidence intervals for these four proportions, then, are:

**Proportion and CI for "Govt Help Blks"**

CI for 2012: `r round(pGovt12, 3)` $\pm$ `r round(meGovt12, 3)`, or (`r round((pGovt12 - meGovt12), 3)`, `r round((pGovt12 + meGovt12), 3)`)

CI for 2008: `r round(pGovt08, 3)` $\pm$ `r round(meGovt08, 3)`, or (`r round((pGovt08 - meGovt08), 3)`, `r round((pGovt08 + meGovt08), 3)`) -->

**Proportion and CI for "No Special Treatment"**

CI for 2012: `r round(pNoSpec12, 3)` $\pm$ `r round(meNoSpec12, 3)`, or (`r round((pNoSpec12 - meNoSpec12), 3)`, `r round((pNoSpec12 + meNoSpec12), 3)`)

CI for 2008: `r round(pNoSpec08, 3)` $\pm$ `r round(meNoSpec08, 3)`, or (`r round((pNoSpec08 - meNoSpec08), 3)`, `r round((pNoSpec08 + meNoSpec08), 3)`)

Now that we understand what we can infer about target population attitudes on this question in these two years of the GSS survey, we can address whether the changes we're seeing in the sample proportions between 2008 and 2012 are significant. We do this now in answer to the following question.

### Question 2 - Differences Between Two Proportions

*Q: How did the level of support/resistance change between the years of Obama's election and re-election, and is this change significant?*

We know that the `helpblk` proportions for the `Govt Help Blks` and `No Special Treatment` responses are not the same in 2008 vs. 2012. But are the differences in those proportions statistically significant? To find out, we'll up a hypothesis test, starting with the `Govt Help Blks` response that affirms the belief that the government has a role to play in addressing and ameliorating the present-day effects of the history of race relations in the U.S. 

Our null hypothesis will be that there is no significant difference between the proporation of the target population who would provide this response in 2008 and in 2012 (with any difference detected with the "noise" level produced by the happenstance of sample); our alternative hypothesis will be that the difference we detect is significant beyond the noise level we might expect:

$$H0: p08 - p12 = 0$$
$$Ha: p08 - p12 x= 0$$
Our conditions for conducting this test in relation to the Central Limit Theoresm remain in place: the samples are independent and and the size/skew of our sample raises no red flags.

so then (obs - null)/se 

With se = pooled proportion.

```{r figuring-out-difference}

# Write stuff
# Construct hypothesis (conditions)
# Don't forget about pooled porportion
# Figure out diff for yes-help: manually, then with inference formula
# Figure out diff for no-special: manually, then with inference formula

# Remind ourselves of how many answered this question in each year:

nhelpblk08
nhelpblk12

# How many answered "Govt Help Blks" affirmatively in each year

GovtSuccess08 <- gss %>% filter(year == '2008' & !is.na(helpblk) & helpblk == 'Govt Help Blks') %>%
  summarise(countGov08 = n())

GovtSuccess12 <- gss %>% filter(year == '2012' & !is.na(helpblk) & helpblk == 'Govt Help Blks') %>%
  summarise(countGov12 = n())

# And in what proportion

pGovt08
pGovt12

# What is the different in that proportion

pDiff <- pGovt12 - pGovt08
pDiff

# Since this is a null hypothesis, what is our null proportion for the difference

nullProp <- 0
nullProp

# For the pooled proportion in the standard error, we'll need the total number of "successes"
# on this question from both years

GovtSuccess08 <- as.numeric(GovtSuccess08)
GovtSuccess12 <- as.numeric(GovtSuccess12)

GovtSuccess08
GovtSuccess12

# Then the pooled proportion is the # of successes divided by the number of total respondents

pPool <- (GovtSuccess08 + GovtSuccess12)/(nhelpblk08 + nhelpblk12)
pPool

# The standard error is the square root of the sum of the pooled proportion divided by
# the number of responses for both years

seGovt <- sqrt((pPool*(1-pPool))/nhelpblk08 + (pPool*(1-pPool))/nhelpblk12)
seGovt

# The z score, as always, is the observed value less the null value divided by the standard error

z_score <- (pDiff - nullProp) / seGovt
z_score

# And the p-value is the one associated with this Z-score.

pnorm(pDiff, nullProp, seGovt) # should this be 2x?




```

## Limitations and Future Directions

The implications of my findings are that, between 2008 and 2012, attitudes among the general adult, non-institutionalized U.S. population hardened against the idea that the government had a role in addressing the historical and structural inequalities faced by African American citizens. And, one could speculate, this shift was part of a backlash against the 2008 election of the U.S.'s first black president and a hint at the swing to the right that anticipated the 2016 election of Donald J. Trump. 

But there are two significant questions we might ask that would complicate this narrative.

1. First, we might want to ask if this shift had anything in particular to do with race, or whether it was part of a more general shift of the sort that brought the "Tea Party" wave in the 2010 midterm elections. Were changes in attitude with respect to federal intervention in race matter sharper than that broader shift against the idea of government intervention in general? In particular, were the changes more significant than those in areas coded as non-racial, such as the GSS questions about the government's role in providing access to healthcare or addressing income inequality? 

2. And, second, was the change between 2008 and 2012 part of a larger historical trend or a blip in the larger narrative? In this sense, the answer to the GSS `helpblk` question in 2016 -- the year of Trump's electoral victory -- is interesting and instructive, as we'll see below:

```{r comparison-to-2016}

# Earlier in this analysis, we gathered the relevant data for 2016. Remember the results we found,
# based upon the full uncleaned GSS dataset:

# gssFull %>% filter(YEAR == 2016, !is.na(HELPBLK)) %>% group_by(HELPBLK) %>% summarise(count = n())

#  HELPBLK              count
#  <fct>                <int>
# 1 GOVT HELP BLKS         246
# 2 2                      220
# 3 AGREE WITH BOTH        608
# 4 4                      371
# 5 NO SPECIAL TREATMENT   430
# TOTAL                   1875

nhelpblk2016 = 1875



```